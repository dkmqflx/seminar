- 1990년 중반까지 는 모두 다 Static 사이트 였다.

- 서버에 이미 잘 만들어진 html 문서들이 있고 사용자가 브라우저에서 www.hello.com 과 같은 주소에 접속하면

- 서버에 이미 배포 되어져 있는 html 문서를 받아 와서 보여 주는 방식

- 이 방법의 한 가지 문제점은 페이지 내에서 다른 링크를 클릭하면 다시 서버에서 해당 페이지의 html 을 받아와서 페이지 전체가 업데이트 되기 때문에 페이지를 이동할 때 마다 깜빡 거리는 현상이 일어나서 사용성이 떨어진다.

<br/>

- 1996년에 또 다른 문서를 담을 수 있는 ifram 태그가 도입이 되었고 이제는 페이지 내에서 부분적으로 문서를 받아서 업데이트 할 수가 있게 된다

- 즉, ifram태그 내에서 www.hello.com/about 과 같은 문서들을 가져와서 업데이트 할수 있는 것이다

- 그리고 1998년 우리가 많이 쓰고 있는 fetch api 에 원조 XMLHttpRequest api 가 개발이 되어서 이제는 html 문서 전체가 아니라 JSON과 같은 포맷으로 가볍게 필요한 데이터만 반할 수 있게 된다

- 그 데이터를 자바스크립트를 이용해서 동적으로 html 요소를 생성해서 페이지에 업데이트 하는 방식

- 2005년 이런 방식이 드디어 공식적인 AJAX 라는 이름을 가지게 되고 구글에서도 AJAX 작성을 이용해서 지메일이나 구글맵 같은 우리가 많이 쓰고 있는 웹 어플리케이션을 만들기 시작한다.

- 이것이 현재 널리 쓰이고 있는 spa , 싱글 페이지 어플리케이션

- 사용자가 한 페이지 내에서 머무르면서 필요한 데이터를 서버에서 받아와서 부분적으로만 업데이트하는데

- 이런 방식으로 하나의 어플리케이션에 사용하듯 웹사이트에서도 사용성이 조금씩 좋아지게 된다.

- 이런 spa 트렌드 그리고 사용자들의 pc 성능이 점차 좋아져서 많은 것들을 무리 없이 처리할 수 있게 되었고 자바스크립트도 표준화가 잘 되어 짐에 따라서 강력한 커뮤니티를 바탕으로 angular, react, vue 같은 프레임워크가 나와서 CSR 클라이언트 사이드 렌더링 시대로 접어들게 된다.

## CSR

- 클라이언트 사이드의 렌더링 이라 쉽게 얘기하면 클라이언트 측에서 다해 먹는 걸 말하는데

- 서버에서 index.html 파일을 클라이언트의 보내주면 CSR 에서 사용되는 가상 추상적이고 심플한 html 예제를 보면 아래처럼

- body 안에는 id 루트만 달랑 하나만 들어 있고 어플리케이션에서 필요한 자바 스크립트의 링크만 들어가 있다.

```html
<body>
  <div id="root"></div>
  <script src="app.js"></script>
</body>
```

- 그래서 html은 텅 텅 비어져 있기 때문에 처음에 접속하면 빈 화면만 보이고 다시 링크된 어플리케이션 자바스크립트를 서버로 부터 다운로드 받게 되는데

- 여기 자바스크립트는 우리 어플리케이션에서 필요한 로직들 뿐만 아니라 어플리케이션을 구동하는 프레임워크와 라이브러리의 소스 코드 들도 다 포함이 되어져 있습니다

- 그렇기 때문에 굉장히 사이즈가 커서 다운로드 받는데도 시간이 소요될 수 있겠죠

- 추가로 필요한 데이터가 있다면 서버에 요청해서 데이터를 받아 다음에 이것들을 기반으로 해서 동적으로 html을 생성해서 드디어 사용자에게 최종적인 어플리케이션을 보여주게 됩니다

- 클라이언트 사이드의 렌더링에 큰 문제점으로는 사용자가 첫 화면에 보기까지 시간이 오래 걸릴 수 있다는 점과

- 두번째로는 썩 좋지 않는 seo 를 꼽을 수 있습니다

- SEO란 Search Engine Optimization의 약자로 구글 네이버 와 같은 검색 엔진들은 서버 에 등록된 웹사이트를 하나 하나씩 돌아다니면서 웹 사이트의 html 문서를 분석해서

- 여기 html 은 이런 title과 meta태그에 descrioption 옵션이 있으니까 이런 검색어로 찾아질 수 있는 웹사이트이다

- 그리고 여기에 이런 링크들이 있으니까 이것도 검색엔진에 등록해 놔야 겠어 라고 판단해서 우리가 검색할 때 웹 사이트를 빠르게 검색할 수 있게 도와준다.

- 하지만 csr 에서 사용되어지고 있는 html body는 대부분 텅 텅 비어져 있기 때문에 검색엔진들이 CSR로 작성된 웹 페이지를 분석하는 데 많은 어려움을 겪고 있고 있다.

- 구글에서는 조금 개선이 되었지만 여전히 seo 가 좋지 않다

- 이런 CSR의 과도한 문제점들 때문에 우리가 1990년 중반 쯤에 사용했던 static 에서 영감을 받은 SSR이 도입된다.

## SSR

- 이제 클라이언트에서 모든 것을 처리하는 방식과는 다르게 웹사이트에 접속하면 이제 서버에서 필요한 데이터를 모두 가져와서 html 파일을 만들게 되고 이렇게 잘 만들어진 html 파일을 동적으로 조금 제어할 수 있는 JS 소스 코드와 함께 클라이언트에게 보내주게 된다.

- 그 다음에 클라이언트 상에서는 잘 만들어진 html 문서를 받아서 바로 사용자에게 보여줄 수 있다.

- 이런 html을 이용하게 되면 CSR 을 사용했을 때보다 첫 번째 페이지 로딩이 빨라지는 장점이 있고

- 두번째로는 모든 컨텐츠가 HTML에 담겨져 있기 때문에 조금 더 효율적인 seo 를 할 수가 있다.

- 하지만 SSR에도 큰 문제점이 존재하는데

- 첫번째로는 static site에서 발생했던 블링킹 이슈가 여전히 존재한다.

- 사용자가 클릭을 하게 되면 전체적인 웹사이트를 다시 서버에서 받아온 것과 동일하기 때문에 썩 좋지 않는 user experience를 겪을 수가 있다.

- 두번째로는 서버에 과부하가 걸리기 쉽다.

- 특히 사용자가 많은 제품일수록 사용자가 클릭을 할 때마다 서버에 요청해서 접어 에서 필요한 데이터를 가지고 와서 html에 를 만들어야 하므로 서버에 과부하가 걸리기가 쉽다.

- 그리고 세번째 정말 치명적인 단점으로는 사용자가 빠르게 웹 사이트를 확인할 수는 있지만 동적 으로 데이터를 처리하는 자바스크립트를 아직 다운로드 받지 못해서 여기저기 클릭했는데 반응이 없는 경우가 발생할 수 있습니다

## TTV(Time To View), TTI(Time To Interact)

- 이곳이 무슨 말인지 이해 하려면 TTV와 TTI 두 가지에 대해서 잘 살펴볼 필요가 있다.

- CSR과 SSR을 시간이 흘러가는 순서대로 분석해보면 CSR은 사이트에 접속하게 되면 서버에게서 인덱스 파일을 받아오고

- 인덱스 파일은 텅 텅 비어져 있기 때문에 사용자에게는 아무것도 보여주지 않고

- 이에 html의 파일에 링크 되어져 있는 이 웹 사이트에서 필요한 모든 로직이 담겨 있는 자바스크립트를 요청하게 된다.

- 그리고 최종적으로 동적으로 html을 생성할 수 있는 웹 어플리케이션 로직이 담긴 자바스크립트 파일을 받아 오게 된다.

- 그리고 이 순간부터 웹사이트가 사용자에게 보여 지게 되고 또 사용자가 클릭이 가능하게 된다.

- CCR은 TTV, 사용자가 웹 사이트를 볼 수 있음과 동시에 TTI 클릭을 하거나 인터랙션이 가능하게 됩니다

<br/>

- 반대로 SSR은 사이트에 접속을 하게 되면 서버에서 이미 잘 만들어진 인덱스 파일을 받아오게 되고 사용자가 웹 사이트를 볼 수가 있다

- 하지만 아직 동적으로 제어할 수 있는 자바 스크립트 파일은 받아 오지 않았으므로 사용자가 클릭을 해도 아무런 것도 처리할 수가 없다

- 그래서 최종적으로 자바스크립트 파일을 서버에서 받아와야 지만 그 때부터 사용자의 클릭을 처리할 수 있는 인터랙션이 가능해진다

- 그래서 CSR은 사용자가 사이트를 볼 수 있는 시간과 실제로 인터랙션 할 수 있는 시간의 공백기간이 꽤 긴 편이다

- 그래서 웹 사이트의 성능을 분석할 때 TTV와 TTI도 중요한 metic으로 사용할 수 있다.

- CSR을 사용한다면 우리가 최종적으로 번들링에서 사용자에게 보내주는 이 자바스크립트 파일을 어떻게 하면 효율적으로 많이 분할해서 첫번째로 사용자가 보기 위해서 필요한 정말 필수적인 아이만 보낼 수 있을지 고민해 보면 좋다

- SSR 같은 경우는 사용자가 보고 인터랙션하는 이 시간에 단차를 줄이기 위해서 어떤 노력을 할 수 있을지

- 우리가 어떻게 조금 더 매끄러운 ui 와 ux 를 제공할 수 있을지 고민해 보면 좋다.

## SSG

- 그리고 요즘에는 꼭 CSR 또는 SSR을 고집해서 사용하기 보다는 SSG도 있다

- SSG는 Static Site Generation의 약자로 리액트 같은 경우는 클라이언트 사이드의 렌더링에 특화된 라이브러리 이지만 개츠비라는 라이브러리와 함께 사용하면 리액트 로 만든 웹 어플리케이션을 정적으로 웹 페이지를 생성을 미리 해 두어서 서버에 배포에 놀 수가 있다.

- 그리고 이렇게 만들어진 웹 사이트들은 모두 다 정적인 것은 아니다

- 우리가 추가적으로 데이터를 서버에서 받아 오거나 또는 동적 으로 처리해야 되는 로직이 있다면 자바스크립트 파일을 함께 가지고 있을 수 있기 때문에 동적인 요소도 충분히 추가할 수가 있다.

- 그리고 개츠비 다음으로 리액터 에서 많이 사용되는 것이 next.js

- next.js는 강력한 서버 사이즈로 렌더링을 지원하는 라이브러리

- 요즘에는 SSG 도 지원을 하고 SSR과 CSR을 잘 섞어서 조금 더 강력하고 유연하게 우리의 목적에 맞게 사용할 수 있도록 지원해주고 있다

---

- CSR, SSR, SSG 중 어떤 것이 최고다 라고 하기 보다는 우리의 사이트는 정적인 사이트인지 서버에서 동적으로 데이터를 받아오는지 얼마나 자주 얼마나 많은 사용자가 있는지에 따라서 TTV와 TTI를 고려해서 조금 더 유연하게 섞어가면서 개발해 나가시면 좋을 것

---

## Reference

- [서버사이드 렌더링 (개발자라면 상식으로 알고 있어야 하는 개념 정리 ⭐️)](https://www.youtube.com/watch?v=iZ9csAfU5Os)
